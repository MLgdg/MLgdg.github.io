---
layout:     post
title:      论文阅读-GPT3
subtitle:   
date:       2022-07-15
author:     高庆东
header-img: img/ceshi.jpg
catalog: true
tags:
    - 生成模型
    - GPT
---


论文核心：0样本训练或者少样本训练 要理解one-shot 和 zero-shot训练
## 数据
提示学习，构建提示  
https://www.promptingguide.ai/zh/introduction/examples

## 模型
模型结构和12没啥区别按照参数初始化模型600G有点大，搞不动  
学习一下FSDP应该能训练起来  
具体细节的模型调整真的不知道了论文也没说比如从GPT1到GPT2  
只是把标准化层往里移动了，参数初始化方式也不一样

## 训练方式
GPT-3使用方法：

Few-Shot（FS）：指的是在推理时对模型进行一些任务相关的示例演示，但不允许权重更新。  
对于一个典型的数据集，一个示例具有上下文和所需的补全（例如英语句子和对应的法语句子），  
并通过给出K个示例上下文和补全的例子进行了Few-Shot。我们通常将K设置在10到100的范围内。  
FS的主要优点是，大大减少了对特定任务数据的需求，并减少了过拟合的可能性。主要缺点是，  
到目前为止，这种方法的结果要比最新的微调模型差很多。而且，仍然需要少量的任务特定数据

零样本1样本或者少样本都是不更新梯度的使用方式是 把问题描述、样本、带预测样本拼起来  
然后输入模型等输出
![GPT3](/img/20230313/gpt3.png)


---
layout:     post
title:      论文-EfficientDet
subtitle:   
date:       2020-02-02
author:     高庆东
header-img: img/ceshi.jpg
catalog: true
tags:
    - EfficientDet
    - 目标检测
    - FPN
    - 非极大值抑制
    - NAS
    - 
---

### 创新点
这个文章还挺不错的，性能上应该说比较好，激活函数的创新真的会对性能造成质的改变吗？这是一个值得深思的问题。  
创新点在于一个双向特征金字塔网络同时为了减小计算量使用了一些可分离卷积核，在计算回归损失得时候使用  
了FocalLoss损失，
首先是FPN金字塔网络，而且是双向的，看一下图
![双向fpn](/img/双向FPN.png)  
图中就是正常的卷积，每个卷积都是空间分离卷积核点卷积的组合对这事为了减少参数量。圆圈部分有一下几步操作  
1.输入的部分对于大小不齐的需要采样尽心补齐，  
2.几个输入进行带权值的叠加。  
3.权值叠加完后进行经过swish激活  
4.经过激活后的数据通过空间分类间距核点卷积，每个输出都是一样的  
这就是骨架部分，输出的时候将五个输出先变形，变成回归和类别，然后输出。  

### 训练阶段  
和FasterRCNN一样也是构建9个不同比例的锚点框。所以最后的box和class通道需要乘9 
构建数据的时候和FasterRCNN很像。分类的时候使用FocalLoss作为损失函数。所有的框都参与训练  
同时有个阈值，IOU小于0.4的全是分类训练的负样本，IOU大于0.5的全是正样本，正样本种的目标会被设为1  
然后训练，损失使用FocalLoss
在回归阶段依然使用IOU大于0.5的样本进行回归训练。

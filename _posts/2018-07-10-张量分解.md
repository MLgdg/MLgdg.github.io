---
layout:     post
title:      矩阵补全协同过滤
subtitle:   
date:       2018-07-10
author:     高庆东
header-img: img/ceshi.jpg
catalog: true
tags:
    - 张量分解
    - 网络加速
    - 矩阵分解
    - 协同过滤
    - 矩阵不全
    - 神经网络加速
---

## 协同过滤
有些用户有些商品，某些用户已经给出了某些商品的评分，需要根据用户

的已知评分来推断未某些用户对某些商品可能被评多少分。其本质是补全

矩阵。矩阵分解是补全矩阵的主要方法，首先估计出分解矩阵是什么。然

后计算缺失值。

- 协同：找到共同的偏好信息
- 过滤：给出预测

# 矩阵分解

## Basic MF
Basic MF是最基础的分解方式，将评分矩阵R分解为用户矩阵U和项目矩

阵S， 通过不断的迭代训练使得U和S的乘积越来越接近真实矩阵，矩阵

分解过程如图： 

![矩阵分解](/img/矩阵分解.png)

预测值接近真实值就是使其差最小，这是我们的目标函数，然后采用

梯度下降的方式迭代计算U和S，它们收敛时就是分解出来的矩阵。我

们用损失函数来表示误差（等价于目标函数）： 

![矩阵分解损失函数](/img/矩阵分解损失函数)

上式中R_ij是评分矩阵中已打分的值，U_i和S_j相当于未知变量。

为求得公式1的最小值，相当于求关于U和S二元函数的最小值

（极小值或许更贴切）。通常采用梯度下降的方法： 

![矩阵分解损失函数跟新公式](/img/矩阵分解损失函数跟新公式.png)

学习率设为1.5较为合适


# 截断SVD加速网络

网络的输出等于 Ax+b

对权值矩阵A进行分解 分解的对角矩阵只保留最大值再解得 A^

![svd分解](/img/svd分解.png)

A^与A具有类似的F范数 

![svd分解网络](/img/svd分解网络.png)

对于原始网络一层一共有n*m个参数也就是A矩阵的个数

使用svd后由以上公式可以将网络看成两层网络

第一层的权重为	SV 偏置为0

第二层的权重为    U  偏置为b

参数个数为 t*m+t*n 


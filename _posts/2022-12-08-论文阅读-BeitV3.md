---
layout:     post
title:      Loss
subtitle:   
date:       2022-12-07
author:     高庆东
header-img: img/ceshi.jpg
catalog: true
tags:
    - 多模态
    - Transformer
---

## 多模态大模型
延用了Beitv2的训练方式不通点在于  
1、多模态
同时输入文本图像的图文对
建设一个专家系统，每个模态对应了一个专家系统  
起始就是每个模态对应一下全连接，训练方式除了v2版本的还有一些模态匹配的  
任务，综合起来就是mask data modeling 还原被mask的部分


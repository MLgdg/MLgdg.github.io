---
layout:     post
title:      论文阅读-CLIP
subtitle:   
date:       2022-02-15
author:     高庆东
header-img: img/ceshi.jpg
catalog: true
tags:
    - CLIP
---

## 噪声对比损失，NCE （triple Loss）
一个batchszie 输入10个图片，这是个图片相互比较，1个正样本 9个负样本
## 使用Adam训练
3学习率衰减  cosine schedule 

## 结构
文本使用的是因果mask  
图像部分使用的pre—LN   
使用的最大index_id 起始就是最后一个位置 因为在数据中eot  
token在在表的最后一个位置，也就是最大位置，等价于取-1位置
'''  
    def encode_text(self, text):
        x = self.token_embedding(text).type(self.dtype)  # [batch_size, n_ctx, d_model]

        x = x + self.positional_embedding.type(self.dtype)
        x = x.permute(1, 0, 2)  # NLD -> LND
        x = self.transformer(x)
        x = x.permute(1, 0, 2)  # LND -> NLD
        x = self.ln_final(x).type(self.dtype)

        # x.shape = [batch_size, n_ctx, transformer.width]
        # take features from the eot embedding (eot_token is the highest number in each sequence)
        x = x[torch.arange(x.shape[0]), text.argmax(dim=-1)] @ self.text_projection

        return x  
'''  
上三角是倒三角  下三角是正三角  
---
layout:     post
title:      对于cnn的理解
subtitle:   
date:       2017-07-06
author:     高庆东
header-img: img/ceshi.jpg
catalog: true
tags:
    - cnn
    - 卷积
    - 网络结构
---


## 我对于cnn网络的一些理解

cnn进行卷积运算的时候当从前一层卷积往下一层的时候 首先确定上一层得

到featuer map 的个数 k

然后确定当前层需要多少feature map 然后确定卷积核的大小m*n  该层

的权重矩阵等于=卷积核的维度 乘上一层feature map 的个数=m*n*k

每层的权值个数与上一层的featuer map 的个数有关系

该层每个神经元的输入等于=m*n乘上层某个featuer map （将所有的

featuer map 乘一遍后 加起来）


对于rgb三通道 卷积时filter时rgb三个维度的 对应相乘在相加会生成一

维的featuer map


pool过程不需要加权重只是单纯为了减小神经元个数  （一般没有参数）

卷积层和池化层的区别！！！！！！！！！！！！！！！！！！！

每一层的残差其实就是损失函数对于该层激活值的导数 （激活值时没有进

入激活函数时的值）和和权重和偏置有直接关系

一个filter=n*m*上一层feature map的个数（也可以自己定义） 。对应

一个偏置数b

cnn中对于每个权值都可以设置一个学习率
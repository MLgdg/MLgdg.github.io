---
layout:     post
title:      kaggle竞赛总结分析-孟加拉语预测
subtitle:  
date:       2019-01-28
author:     高庆东
header-img: img/ceshi.jpg
catalog: true
tags:
    - python
    - pytorch
    - densenet
    - 多标签分类
---
### 题目
这个主要是做孟加拉语识别，孟加拉语是个非常其他的文字。每个字有三种属性相当于一个多标签分类问题。  
标签间的耦合性相对较低，我使用三个不同的模型训练每个标签然后再组装

### 数据
读取parquet格式数据需要一个特殊的引擎
```
import torch
import torchvision
from PIL import Image
import os
import pandas as pd
import numpy as np
df = pd.read_parquet('./test_image_data_3.parquet',engine='pyarrow')
df_n=df.values
image_name=df_n[:,0]
image=df_n[:,1:]
for i in range(len(df_n)):
    image_TR=Image.fromarray(np.array(image[i].reshape(137,236),np.uint8))
    image_TR.save('./test_data/{}.jpg'.format(image_name[i]))
```
当数据量较大的时候我逐行读取
```
df = pd.read_parquet('./train_image_data_0.parquet',engine='pyarrow')
df_n=df.values
image_name=df_n[:,0]
image=df_n[:,1:]
for i in range(len(df_n)):
    image_TR=Image.fromarray(np.array(image[i].reshape(137,236),np.uint8))
    image_TR.save('./train_data/{}.jpg'.format(image_name[i]))
 ```
 
### 训练
我使用了densenat121模型，使用torch创建好的构建模型  
#### 生成训练数据
```
import torch
import torchvision
from PIL import Image
import os
import pandas as pd
import numpy as np

root='./train_data/'
train_data=pd.read_csv('./train.csv')

class data_set(torch.utils.data.Dataset):
    def __init__(self,train_data,x=3):
        self.train_image_name=train_data.values[:,0]
        self.train_image_target=train_data.values[:,x]
    
    def __getitem__(self,ind):
        image_path=root+self.train_image_name[ind]+'.jpg'
        image=torch.from_numpy(np.array(Image.open(image_path),np.float32)).unsqueeze(0)
        target=self.train_image_target[ind]
        return image,target
    def __len__(self):
        return len(self.train_image_target)

train_data_set=data_set(train_data)
train_data_set_loader=torch.utils.data.DataLoader(train_data_set,32,shuffle=True)
```
创建模型
```
model = torchvision.models.densenet121(pretrained=True)
model.features.conv0=torch.nn.Conv2d(1, 64, kernel_size=7, stride=2)
model.classifier = torch.nn.Linear(1024, 7)
```
创建损失和优化器
```
oss_f=torch.nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)
```
#### 训练
使用我电脑的1060显卡，需要12小时左右
```
model.cuda()
for i in range(10):
    k=0
    for img,tar in train_data_set_loader:
        optimizer.zero_grad()
        out=model(img.cuda())
        out=out.to('cpu')
        Loss=Loss_f(out,tar)
        Loss.backward()
        optimizer.step()
        k=k+1
        if k%100==0:
            print ("第 {} epoch第 {} batch的loss={}".format(i,k,Loss))
    torch.save(model,'./mode_zoo/mode_7分类{}loass-{}.pth'.format(i,Loss))
```
